{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNoquKKTmRkJZfUX16kJ9K6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jahnavirishikesh/contradiction_detection/blob/main/contradiction_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsHBiFndM_ud",
        "outputId": "8ddcc00d-0020-4421-c5f2-d854ac38d12e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy tensorflow keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1_z7l7DMVqN",
        "outputId": "da7a6aa6-3cb9-4be7-aa4d-ae97bf950cb7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "j3KU-Iru6v95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce5dc15f-7f5e-47ba-d493-ee18060aaf06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-df3f75e791bb>:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_train['SENTENCE A'] = X_train['SENTENCE A'].apply(clean_text)\n",
            "<ipython-input-37-df3f75e791bb>:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_train['SENTENCE B'] = X_train['SENTENCE B'].apply(clean_text)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_27            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_13 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │        \u001b[38;5;34m250,600\u001b[0m │ input_layer_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                           │                        │                │ input_layer_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m234,496\u001b[0m │ embedding_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m234,496\u001b[0m │ embedding_13[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │         \u001b[38;5;34m25,700\u001b[0m │ bidirectional_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │         \u001b[38;5;34m25,700\u001b[0m │ bidirectional_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dot_26 (\u001b[38;5;33mDot\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ bidirectional_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dot_27 (\u001b[38;5;33mDot\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ bidirectional_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_max_pooling1d_26   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dot_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_max_pooling1d_27   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dot_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_13            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dropout_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m65,664\u001b[0m │ dropout_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dropout_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dense_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_27            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">250,600</span> │ input_layer_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                           │                        │                │ input_layer_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │ embedding_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │ embedding_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │ bidirectional_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │ bidirectional_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dot_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ bidirectional_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dot_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ bidirectional_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_max_pooling1d_26   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_max_pooling1d_27   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_13            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dropout_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dropout_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m844,977\u001b[0m (3.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">844,977</span> (3.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m844,977\u001b[0m (3.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">844,977</span> (3.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with batch size: 32\n",
            "Epoch 1/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.6757 - loss: 0.6395 - val_accuracy: 0.8555 - val_loss: 0.4837 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.6863 - loss: 0.6164 - val_accuracy: 0.8534 - val_loss: 0.4299 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7535 - loss: 0.5139 - val_accuracy: 0.8637 - val_loss: 0.3260 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8397 - loss: 0.3833 - val_accuracy: 0.8657 - val_loss: 0.2977 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8515 - loss: 0.3393 - val_accuracy: 0.8596 - val_loss: 0.3230 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.8597 - loss: 0.3161 - val_accuracy: 0.8623 - val_loss: 0.3409 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.8735 - loss: 0.2902 - val_accuracy: 0.8637 - val_loss: 0.3975 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.8834 - loss: 0.2659 - val_accuracy: 0.8521 - val_loss: 0.4711 - learning_rate: 2.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.8887 - loss: 0.2505 - val_accuracy: 0.8473 - val_loss: 0.4824 - learning_rate: 2.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8937 - loss: 0.2388 - val_accuracy: 0.8487 - val_loss: 0.5715 - learning_rate: 2.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.8985 - loss: 0.2266 - val_accuracy: 0.8473 - val_loss: 0.5312 - learning_rate: 4.0000e-05\n",
            "Epoch 12/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9016 - loss: 0.2302 - val_accuracy: 0.8480 - val_loss: 0.5061 - learning_rate: 4.0000e-05\n",
            "Epoch 13/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9005 - loss: 0.2205 - val_accuracy: 0.8466 - val_loss: 0.5258 - learning_rate: 4.0000e-05\n",
            "Epoch 14/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9039 - loss: 0.2214 - val_accuracy: 0.8446 - val_loss: 0.5194 - learning_rate: 8.0000e-06\n",
            "Epoch 15/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.9035 - loss: 0.2192 - val_accuracy: 0.8453 - val_loss: 0.5213 - learning_rate: 8.0000e-06\n",
            "Epoch 16/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9033 - loss: 0.2141 - val_accuracy: 0.8439 - val_loss: 0.5245 - learning_rate: 8.0000e-06\n",
            "Epoch 17/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.8992 - loss: 0.2222 - val_accuracy: 0.8439 - val_loss: 0.5246 - learning_rate: 1.6000e-06\n",
            "Epoch 18/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9024 - loss: 0.2175 - val_accuracy: 0.8439 - val_loss: 0.5242 - learning_rate: 1.6000e-06\n",
            "Epoch 19/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9012 - loss: 0.2247 - val_accuracy: 0.8439 - val_loss: 0.5242 - learning_rate: 1.6000e-06\n",
            "Epoch 20/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9045 - loss: 0.2125 - val_accuracy: 0.8439 - val_loss: 0.5244 - learning_rate: 1.0000e-06\n",
            "Epoch 21/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.8987 - loss: 0.2180 - val_accuracy: 0.8439 - val_loss: 0.5238 - learning_rate: 1.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9060 - loss: 0.2150 - val_accuracy: 0.8439 - val_loss: 0.5245 - learning_rate: 1.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9079 - loss: 0.2103 - val_accuracy: 0.8439 - val_loss: 0.5246 - learning_rate: 1.0000e-06\n",
            "Epoch 24/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9019 - loss: 0.2240 - val_accuracy: 0.8439 - val_loss: 0.5238 - learning_rate: 1.0000e-06\n",
            "Epoch 25/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9104 - loss: 0.2172 - val_accuracy: 0.8439 - val_loss: 0.5247 - learning_rate: 1.0000e-06\n",
            "Epoch 26/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9059 - loss: 0.2129 - val_accuracy: 0.8439 - val_loss: 0.5243 - learning_rate: 1.0000e-06\n",
            "Epoch 27/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9091 - loss: 0.2141 - val_accuracy: 0.8439 - val_loss: 0.5251 - learning_rate: 1.0000e-06\n",
            "Epoch 28/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9060 - loss: 0.2143 - val_accuracy: 0.8439 - val_loss: 0.5254 - learning_rate: 1.0000e-06\n",
            "Epoch 29/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9010 - loss: 0.2181 - val_accuracy: 0.8439 - val_loss: 0.5252 - learning_rate: 1.0000e-06\n",
            "Epoch 30/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9025 - loss: 0.2144 - val_accuracy: 0.8432 - val_loss: 0.5251 - learning_rate: 1.0000e-06\n",
            "Epoch 31/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9032 - loss: 0.2167 - val_accuracy: 0.8432 - val_loss: 0.5253 - learning_rate: 1.0000e-06\n",
            "Epoch 32/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9055 - loss: 0.2139 - val_accuracy: 0.8439 - val_loss: 0.5256 - learning_rate: 1.0000e-06\n",
            "Epoch 33/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9036 - loss: 0.2141 - val_accuracy: 0.8439 - val_loss: 0.5256 - learning_rate: 1.0000e-06\n",
            "Epoch 34/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9054 - loss: 0.2124 - val_accuracy: 0.8432 - val_loss: 0.5263 - learning_rate: 1.0000e-06\n",
            "Epoch 35/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9093 - loss: 0.2117 - val_accuracy: 0.8432 - val_loss: 0.5259 - learning_rate: 1.0000e-06\n",
            "Epoch 36/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.9074 - loss: 0.2139 - val_accuracy: 0.8432 - val_loss: 0.5262 - learning_rate: 1.0000e-06\n",
            "Epoch 37/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9056 - loss: 0.2160 - val_accuracy: 0.8439 - val_loss: 0.5253 - learning_rate: 1.0000e-06\n",
            "Epoch 38/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9086 - loss: 0.2126 - val_accuracy: 0.8439 - val_loss: 0.5253 - learning_rate: 1.0000e-06\n",
            "Epoch 39/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9035 - loss: 0.2133 - val_accuracy: 0.8439 - val_loss: 0.5254 - learning_rate: 1.0000e-06\n",
            "Epoch 40/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9052 - loss: 0.2138 - val_accuracy: 0.8439 - val_loss: 0.5260 - learning_rate: 1.0000e-06\n",
            "Epoch 41/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8999 - loss: 0.2174 - val_accuracy: 0.8439 - val_loss: 0.5254 - learning_rate: 1.0000e-06\n",
            "Epoch 42/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9020 - loss: 0.2153 - val_accuracy: 0.8432 - val_loss: 0.5255 - learning_rate: 1.0000e-06\n",
            "Epoch 43/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9053 - loss: 0.2159 - val_accuracy: 0.8439 - val_loss: 0.5251 - learning_rate: 1.0000e-06\n",
            "Epoch 44/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9075 - loss: 0.2090 - val_accuracy: 0.8432 - val_loss: 0.5256 - learning_rate: 1.0000e-06\n",
            "Epoch 45/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9072 - loss: 0.2156 - val_accuracy: 0.8432 - val_loss: 0.5262 - learning_rate: 1.0000e-06\n",
            "Epoch 46/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9051 - loss: 0.2116 - val_accuracy: 0.8432 - val_loss: 0.5265 - learning_rate: 1.0000e-06\n",
            "Epoch 47/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9006 - loss: 0.2146 - val_accuracy: 0.8432 - val_loss: 0.5264 - learning_rate: 1.0000e-06\n",
            "Epoch 48/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9086 - loss: 0.2137 - val_accuracy: 0.8432 - val_loss: 0.5267 - learning_rate: 1.0000e-06\n",
            "Epoch 49/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9062 - loss: 0.2183 - val_accuracy: 0.8432 - val_loss: 0.5268 - learning_rate: 1.0000e-06\n",
            "Epoch 50/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9071 - loss: 0.2159 - val_accuracy: 0.8432 - val_loss: 0.5269 - learning_rate: 1.0000e-06\n",
            "Epoch 51/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9083 - loss: 0.2141 - val_accuracy: 0.8432 - val_loss: 0.5277 - learning_rate: 1.0000e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9015 - loss: 0.2159 - val_accuracy: 0.8432 - val_loss: 0.5279 - learning_rate: 1.0000e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9086 - loss: 0.2143 - val_accuracy: 0.8432 - val_loss: 0.5279 - learning_rate: 1.0000e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9082 - loss: 0.2126 - val_accuracy: 0.8432 - val_loss: 0.5276 - learning_rate: 1.0000e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9047 - loss: 0.2169 - val_accuracy: 0.8432 - val_loss: 0.5273 - learning_rate: 1.0000e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9038 - loss: 0.2203 - val_accuracy: 0.8432 - val_loss: 0.5267 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9089 - loss: 0.2102 - val_accuracy: 0.8432 - val_loss: 0.5269 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.8957 - loss: 0.2174 - val_accuracy: 0.8432 - val_loss: 0.5265 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.8968 - loss: 0.2208 - val_accuracy: 0.8425 - val_loss: 0.5264 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9022 - loss: 0.2129 - val_accuracy: 0.8425 - val_loss: 0.5268 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9084 - loss: 0.2113 - val_accuracy: 0.8425 - val_loss: 0.5273 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9050 - loss: 0.2156 - val_accuracy: 0.8412 - val_loss: 0.5272 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9031 - loss: 0.2104 - val_accuracy: 0.8419 - val_loss: 0.5272 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9046 - loss: 0.2201 - val_accuracy: 0.8419 - val_loss: 0.5273 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9030 - loss: 0.2131 - val_accuracy: 0.8425 - val_loss: 0.5276 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9015 - loss: 0.2131 - val_accuracy: 0.8425 - val_loss: 0.5275 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9010 - loss: 0.2141 - val_accuracy: 0.8432 - val_loss: 0.5274 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9042 - loss: 0.2149 - val_accuracy: 0.8425 - val_loss: 0.5274 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.9072 - loss: 0.2149 - val_accuracy: 0.8425 - val_loss: 0.5278 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9059 - loss: 0.2131 - val_accuracy: 0.8432 - val_loss: 0.5279 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9047 - loss: 0.2224 - val_accuracy: 0.8425 - val_loss: 0.5276 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9021 - loss: 0.2138 - val_accuracy: 0.8425 - val_loss: 0.5277 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9018 - loss: 0.2132 - val_accuracy: 0.8425 - val_loss: 0.5279 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9032 - loss: 0.2159 - val_accuracy: 0.8425 - val_loss: 0.5282 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9061 - loss: 0.2158 - val_accuracy: 0.8425 - val_loss: 0.5284 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9031 - loss: 0.2181 - val_accuracy: 0.8419 - val_loss: 0.5282 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9088 - loss: 0.2134 - val_accuracy: 0.8425 - val_loss: 0.5284 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9077 - loss: 0.2094 - val_accuracy: 0.8419 - val_loss: 0.5287 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9010 - loss: 0.2150 - val_accuracy: 0.8425 - val_loss: 0.5293 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9058 - loss: 0.2128 - val_accuracy: 0.8419 - val_loss: 0.5297 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9075 - loss: 0.2104 - val_accuracy: 0.8419 - val_loss: 0.5299 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9069 - loss: 0.2105 - val_accuracy: 0.8419 - val_loss: 0.5297 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9056 - loss: 0.2164 - val_accuracy: 0.8419 - val_loss: 0.5300 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9017 - loss: 0.2121 - val_accuracy: 0.8419 - val_loss: 0.5296 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9062 - loss: 0.2149 - val_accuracy: 0.8419 - val_loss: 0.5299 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9041 - loss: 0.2167 - val_accuracy: 0.8419 - val_loss: 0.5299 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9053 - loss: 0.2155 - val_accuracy: 0.8419 - val_loss: 0.5301 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9053 - loss: 0.2114 - val_accuracy: 0.8419 - val_loss: 0.5312 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9061 - loss: 0.2149 - val_accuracy: 0.8419 - val_loss: 0.5313 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9053 - loss: 0.2159 - val_accuracy: 0.8419 - val_loss: 0.5317 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9033 - loss: 0.2159 - val_accuracy: 0.8419 - val_loss: 0.5312 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9067 - loss: 0.2116 - val_accuracy: 0.8419 - val_loss: 0.5320 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9094 - loss: 0.2126 - val_accuracy: 0.8419 - val_loss: 0.5322 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.9119 - loss: 0.2105 - val_accuracy: 0.8419 - val_loss: 0.5325 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9047 - loss: 0.2174 - val_accuracy: 0.8419 - val_loss: 0.5324 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9098 - loss: 0.2143 - val_accuracy: 0.8419 - val_loss: 0.5326 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9027 - loss: 0.2131 - val_accuracy: 0.8419 - val_loss: 0.5330 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9071 - loss: 0.2139 - val_accuracy: 0.8419 - val_loss: 0.5330 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9030 - loss: 0.2172 - val_accuracy: 0.8419 - val_loss: 0.5330 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.9056 - loss: 0.2139 - val_accuracy: 0.8419 - val_loss: 0.5329 - learning_rate: 1.0000e-06\n",
            "Training with batch size: 64\n",
            "Epoch 1/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9084 - loss: 0.2109 - val_accuracy: 0.8419 - val_loss: 0.5330 - learning_rate: 1.0000e-06\n",
            "Epoch 2/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9082 - loss: 0.2121 - val_accuracy: 0.8412 - val_loss: 0.5328 - learning_rate: 1.0000e-06\n",
            "Epoch 3/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9078 - loss: 0.2070 - val_accuracy: 0.8412 - val_loss: 0.5332 - learning_rate: 1.0000e-06\n",
            "Epoch 4/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9094 - loss: 0.2064 - val_accuracy: 0.8412 - val_loss: 0.5330 - learning_rate: 1.0000e-06\n",
            "Epoch 5/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9051 - loss: 0.2128 - val_accuracy: 0.8412 - val_loss: 0.5329 - learning_rate: 1.0000e-06\n",
            "Epoch 6/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9056 - loss: 0.2146 - val_accuracy: 0.8412 - val_loss: 0.5329 - learning_rate: 1.0000e-06\n",
            "Epoch 7/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9079 - loss: 0.2131 - val_accuracy: 0.8412 - val_loss: 0.5327 - learning_rate: 1.0000e-06\n",
            "Epoch 8/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9038 - loss: 0.2147 - val_accuracy: 0.8412 - val_loss: 0.5324 - learning_rate: 1.0000e-06\n",
            "Epoch 9/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9001 - loss: 0.2175 - val_accuracy: 0.8412 - val_loss: 0.5324 - learning_rate: 1.0000e-06\n",
            "Epoch 10/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9110 - loss: 0.2120 - val_accuracy: 0.8412 - val_loss: 0.5324 - learning_rate: 1.0000e-06\n",
            "Epoch 11/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9106 - loss: 0.2138 - val_accuracy: 0.8412 - val_loss: 0.5324 - learning_rate: 1.0000e-06\n",
            "Epoch 12/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9062 - loss: 0.2149 - val_accuracy: 0.8412 - val_loss: 0.5323 - learning_rate: 1.0000e-06\n",
            "Epoch 13/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9093 - loss: 0.2101 - val_accuracy: 0.8412 - val_loss: 0.5325 - learning_rate: 1.0000e-06\n",
            "Epoch 14/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9059 - loss: 0.2120 - val_accuracy: 0.8419 - val_loss: 0.5328 - learning_rate: 1.0000e-06\n",
            "Epoch 15/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9039 - loss: 0.2120 - val_accuracy: 0.8412 - val_loss: 0.5326 - learning_rate: 1.0000e-06\n",
            "Epoch 16/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9056 - loss: 0.2135 - val_accuracy: 0.8412 - val_loss: 0.5326 - learning_rate: 1.0000e-06\n",
            "Epoch 17/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9099 - loss: 0.2077 - val_accuracy: 0.8419 - val_loss: 0.5332 - learning_rate: 1.0000e-06\n",
            "Epoch 18/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9078 - loss: 0.2193 - val_accuracy: 0.8419 - val_loss: 0.5331 - learning_rate: 1.0000e-06\n",
            "Epoch 19/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9058 - loss: 0.2181 - val_accuracy: 0.8412 - val_loss: 0.5327 - learning_rate: 1.0000e-06\n",
            "Epoch 20/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9088 - loss: 0.2144 - val_accuracy: 0.8412 - val_loss: 0.5329 - learning_rate: 1.0000e-06\n",
            "Epoch 21/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9093 - loss: 0.2155 - val_accuracy: 0.8412 - val_loss: 0.5327 - learning_rate: 1.0000e-06\n",
            "Epoch 22/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9053 - loss: 0.2085 - val_accuracy: 0.8412 - val_loss: 0.5330 - learning_rate: 1.0000e-06\n",
            "Epoch 23/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9055 - loss: 0.2177 - val_accuracy: 0.8412 - val_loss: 0.5333 - learning_rate: 1.0000e-06\n",
            "Epoch 24/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.9082 - loss: 0.2118 - val_accuracy: 0.8412 - val_loss: 0.5335 - learning_rate: 1.0000e-06\n",
            "Epoch 25/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9077 - loss: 0.2062 - val_accuracy: 0.8412 - val_loss: 0.5340 - learning_rate: 1.0000e-06\n",
            "Epoch 26/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9056 - loss: 0.2102 - val_accuracy: 0.8412 - val_loss: 0.5342 - learning_rate: 1.0000e-06\n",
            "Epoch 27/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9103 - loss: 0.2099 - val_accuracy: 0.8419 - val_loss: 0.5347 - learning_rate: 1.0000e-06\n",
            "Epoch 28/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9015 - loss: 0.2098 - val_accuracy: 0.8419 - val_loss: 0.5345 - learning_rate: 1.0000e-06\n",
            "Epoch 29/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9062 - loss: 0.2079 - val_accuracy: 0.8419 - val_loss: 0.5348 - learning_rate: 1.0000e-06\n",
            "Epoch 30/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9093 - loss: 0.2074 - val_accuracy: 0.8419 - val_loss: 0.5350 - learning_rate: 1.0000e-06\n",
            "Epoch 31/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9055 - loss: 0.2098 - val_accuracy: 0.8412 - val_loss: 0.5353 - learning_rate: 1.0000e-06\n",
            "Epoch 32/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9111 - loss: 0.2071 - val_accuracy: 0.8412 - val_loss: 0.5353 - learning_rate: 1.0000e-06\n",
            "Epoch 33/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9084 - loss: 0.2089 - val_accuracy: 0.8412 - val_loss: 0.5357 - learning_rate: 1.0000e-06\n",
            "Epoch 34/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9009 - loss: 0.2112 - val_accuracy: 0.8412 - val_loss: 0.5358 - learning_rate: 1.0000e-06\n",
            "Epoch 35/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9056 - loss: 0.2096 - val_accuracy: 0.8412 - val_loss: 0.5359 - learning_rate: 1.0000e-06\n",
            "Epoch 36/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9032 - loss: 0.2177 - val_accuracy: 0.8412 - val_loss: 0.5357 - learning_rate: 1.0000e-06\n",
            "Epoch 37/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9018 - loss: 0.2160 - val_accuracy: 0.8412 - val_loss: 0.5353 - learning_rate: 1.0000e-06\n",
            "Epoch 38/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9069 - loss: 0.2102 - val_accuracy: 0.8412 - val_loss: 0.5353 - learning_rate: 1.0000e-06\n",
            "Epoch 39/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9073 - loss: 0.2119 - val_accuracy: 0.8412 - val_loss: 0.5355 - learning_rate: 1.0000e-06\n",
            "Epoch 40/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9093 - loss: 0.2098 - val_accuracy: 0.8412 - val_loss: 0.5358 - learning_rate: 1.0000e-06\n",
            "Epoch 41/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9055 - loss: 0.2147 - val_accuracy: 0.8412 - val_loss: 0.5352 - learning_rate: 1.0000e-06\n",
            "Epoch 42/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9019 - loss: 0.2092 - val_accuracy: 0.8412 - val_loss: 0.5358 - learning_rate: 1.0000e-06\n",
            "Epoch 43/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9063 - loss: 0.2146 - val_accuracy: 0.8412 - val_loss: 0.5363 - learning_rate: 1.0000e-06\n",
            "Epoch 44/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9107 - loss: 0.2080 - val_accuracy: 0.8412 - val_loss: 0.5361 - learning_rate: 1.0000e-06\n",
            "Epoch 45/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.9090 - loss: 0.2078 - val_accuracy: 0.8412 - val_loss: 0.5367 - learning_rate: 1.0000e-06\n",
            "Epoch 46/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9079 - loss: 0.2114 - val_accuracy: 0.8412 - val_loss: 0.5369 - learning_rate: 1.0000e-06\n",
            "Epoch 47/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9100 - loss: 0.2124 - val_accuracy: 0.8412 - val_loss: 0.5371 - learning_rate: 1.0000e-06\n",
            "Epoch 48/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.9009 - loss: 0.2186 - val_accuracy: 0.8412 - val_loss: 0.5372 - learning_rate: 1.0000e-06\n",
            "Epoch 49/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9062 - loss: 0.2131 - val_accuracy: 0.8412 - val_loss: 0.5371 - learning_rate: 1.0000e-06\n",
            "Epoch 50/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9021 - loss: 0.2147 - val_accuracy: 0.8412 - val_loss: 0.5365 - learning_rate: 1.0000e-06\n",
            "Epoch 51/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9026 - loss: 0.2133 - val_accuracy: 0.8405 - val_loss: 0.5358 - learning_rate: 1.0000e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9113 - loss: 0.2119 - val_accuracy: 0.8405 - val_loss: 0.5359 - learning_rate: 1.0000e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9062 - loss: 0.2135 - val_accuracy: 0.8412 - val_loss: 0.5359 - learning_rate: 1.0000e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9090 - loss: 0.2089 - val_accuracy: 0.8405 - val_loss: 0.5361 - learning_rate: 1.0000e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9015 - loss: 0.2111 - val_accuracy: 0.8412 - val_loss: 0.5361 - learning_rate: 1.0000e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9087 - loss: 0.2090 - val_accuracy: 0.8405 - val_loss: 0.5357 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9063 - loss: 0.2143 - val_accuracy: 0.8405 - val_loss: 0.5357 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9073 - loss: 0.2060 - val_accuracy: 0.8405 - val_loss: 0.5358 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.9096 - loss: 0.2063 - val_accuracy: 0.8405 - val_loss: 0.5364 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9060 - loss: 0.2154 - val_accuracy: 0.8405 - val_loss: 0.5364 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9065 - loss: 0.2123 - val_accuracy: 0.8405 - val_loss: 0.5361 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.9067 - loss: 0.2104 - val_accuracy: 0.8391 - val_loss: 0.5359 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9065 - loss: 0.2061 - val_accuracy: 0.8398 - val_loss: 0.5361 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9103 - loss: 0.2122 - val_accuracy: 0.8398 - val_loss: 0.5364 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9090 - loss: 0.2113 - val_accuracy: 0.8398 - val_loss: 0.5367 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9021 - loss: 0.2130 - val_accuracy: 0.8398 - val_loss: 0.5362 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9056 - loss: 0.2077 - val_accuracy: 0.8405 - val_loss: 0.5365 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9095 - loss: 0.2109 - val_accuracy: 0.8398 - val_loss: 0.5364 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9066 - loss: 0.2061 - val_accuracy: 0.8398 - val_loss: 0.5366 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9017 - loss: 0.2130 - val_accuracy: 0.8398 - val_loss: 0.5363 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.9062 - loss: 0.2090 - val_accuracy: 0.8398 - val_loss: 0.5363 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9072 - loss: 0.2122 - val_accuracy: 0.8398 - val_loss: 0.5361 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9071 - loss: 0.2124 - val_accuracy: 0.8398 - val_loss: 0.5363 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9086 - loss: 0.2072 - val_accuracy: 0.8398 - val_loss: 0.5367 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.9079 - loss: 0.2073 - val_accuracy: 0.8398 - val_loss: 0.5370 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9087 - loss: 0.2061 - val_accuracy: 0.8398 - val_loss: 0.5368 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9057 - loss: 0.2120 - val_accuracy: 0.8398 - val_loss: 0.5365 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9009 - loss: 0.2103 - val_accuracy: 0.8398 - val_loss: 0.5365 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9045 - loss: 0.2137 - val_accuracy: 0.8398 - val_loss: 0.5366 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.9059 - loss: 0.2102 - val_accuracy: 0.8398 - val_loss: 0.5369 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9038 - loss: 0.2103 - val_accuracy: 0.8398 - val_loss: 0.5371 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9025 - loss: 0.2131 - val_accuracy: 0.8398 - val_loss: 0.5374 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9059 - loss: 0.2111 - val_accuracy: 0.8398 - val_loss: 0.5377 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9095 - loss: 0.2103 - val_accuracy: 0.8398 - val_loss: 0.5381 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9089 - loss: 0.2106 - val_accuracy: 0.8391 - val_loss: 0.5380 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.9048 - loss: 0.2112 - val_accuracy: 0.8391 - val_loss: 0.5378 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9035 - loss: 0.2104 - val_accuracy: 0.8391 - val_loss: 0.5382 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9068 - loss: 0.2088 - val_accuracy: 0.8391 - val_loss: 0.5384 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9055 - loss: 0.2151 - val_accuracy: 0.8391 - val_loss: 0.5384 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.9066 - loss: 0.2073 - val_accuracy: 0.8391 - val_loss: 0.5383 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9088 - loss: 0.2049 - val_accuracy: 0.8391 - val_loss: 0.5389 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.9083 - loss: 0.2117 - val_accuracy: 0.8391 - val_loss: 0.5388 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9024 - loss: 0.2154 - val_accuracy: 0.8391 - val_loss: 0.5383 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9046 - loss: 0.2094 - val_accuracy: 0.8398 - val_loss: 0.5386 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9104 - loss: 0.2096 - val_accuracy: 0.8391 - val_loss: 0.5384 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9016 - loss: 0.2119 - val_accuracy: 0.8398 - val_loss: 0.5380 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9056 - loss: 0.2103 - val_accuracy: 0.8398 - val_loss: 0.5380 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9019 - loss: 0.2130 - val_accuracy: 0.8398 - val_loss: 0.5377 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9105 - loss: 0.2104 - val_accuracy: 0.8405 - val_loss: 0.5381 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9114 - loss: 0.2038 - val_accuracy: 0.8405 - val_loss: 0.5384 - learning_rate: 1.0000e-06\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2637 - loss: nan    \n",
            "Test loss: nan\n",
            "Test accuracy: 0.2078\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, concatenate, Dropout, GlobalMaxPooling1D, Dot\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "import re\n",
        "\n",
        "# Setting random seed for reproducibility\n",
        "seed_value = 42\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "# Load dataset\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Prepare training and testing data\n",
        "X_train = train_data[['SENTENCE A', 'SENTENCE B']]\n",
        "y_train = train_data['label']\n",
        "X_test = test_data[['Question', 'Answer 1', 'Answer 2']]\n",
        "y_test = test_data['label']\n",
        "\n",
        "# Handle missing values\n",
        "X_test = X_test.fillna('')\n",
        "\n",
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "# Clean the text data\n",
        "X_train['SENTENCE A'] = X_train['SENTENCE A'].apply(clean_text)\n",
        "X_train['SENTENCE B'] = X_train['SENTENCE B'].apply(clean_text)\n",
        "X_test['Question'] = X_test['Question'].apply(clean_text)\n",
        "X_test['Answer 1'] = X_test['Answer 1'].apply(clean_text)\n",
        "\n",
        "# Tokenizing and padding data\n",
        "max_sequence_length = 100\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train['SENTENCE A'].tolist() + X_train['SENTENCE B'].tolist())\n",
        "\n",
        "X_train_seq_A = tokenizer.texts_to_sequences(X_train['SENTENCE A'])\n",
        "X_train_seq_B = tokenizer.texts_to_sequences(X_train['SENTENCE B'])\n",
        "X_test_seq_A = tokenizer.texts_to_sequences(X_test['Question'])\n",
        "X_test_seq_B = tokenizer.texts_to_sequences(X_test['Answer 1'])\n",
        "\n",
        "X_train_padded_A = pad_sequences(X_train_seq_A, maxlen=max_sequence_length)\n",
        "X_train_padded_B = pad_sequences(X_train_seq_B, maxlen=max_sequence_length)\n",
        "X_test_padded_A = pad_sequences(X_test_seq_A, maxlen=max_sequence_length)\n",
        "X_test_padded_B = pad_sequences(X_test_seq_B, maxlen=max_sequence_length)\n",
        "\n",
        "# Defining model architecture\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 100\n",
        "\n",
        "input_A = Input(shape=(max_sequence_length,))\n",
        "input_B = Input(shape=(max_sequence_length,))\n",
        "\n",
        "# Attention mechanism function\n",
        "def attention_mechanism(inputs):\n",
        "    attention_scores = Dense(max_sequence_length, activation='softmax')(inputs)\n",
        "    context_vector = Dot(axes=[1, 1])([attention_scores, inputs])\n",
        "    return context_vector\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
        "\n",
        "embedded_A = embedding_layer(input_A)\n",
        "embedded_B = embedding_layer(input_B)\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "lstm_output_A = Bidirectional(LSTM(128, return_sequences=True))(embedded_A)\n",
        "lstm_output_B = Bidirectional(LSTM(128, return_sequences=True))(embedded_B)\n",
        "\n",
        "# Applying attention mechanism to LSTM outputs\n",
        "attention_A = attention_mechanism(lstm_output_A)\n",
        "attention_B = attention_mechanism(lstm_output_B)\n",
        "\n",
        "# Global max pooling for feature extraction\n",
        "pooled_A = GlobalMaxPooling1D()(attention_A)\n",
        "pooled_B = GlobalMaxPooling1D()(attention_B)\n",
        "\n",
        "# Adding dropout layers to prevent overfitting\n",
        "pooled_A = Dropout(0.5)(pooled_A)\n",
        "pooled_B = Dropout(0.5)(pooled_B)\n",
        "\n",
        "# Concatenating pooled outputs from both sentences\n",
        "concatenated_output = concatenate([pooled_A, pooled_B], axis=-1)\n",
        "\n",
        "# Adding Dropout after concatenation for regularization\n",
        "concatenated_output = Dropout(0.5)(concatenated_output)\n",
        "\n",
        "# Dense layers for feature extraction and dropout for regularization\n",
        "dense_layer_1 = Dense(128, activation='relu')(concatenated_output)\n",
        "dense_layer_1 = Dropout(0.5)(dense_layer_1)\n",
        "dense_layer_2 = Dense(64, activation='relu')(dense_layer_1)\n",
        "output = Dense(1, activation='sigmoid')(dense_layer_2)\n",
        "\n",
        "# Define and compile model\n",
        "model = Model(inputs=[input_A, input_B], outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Implementing learning rate reduction on plateau and early stopping callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training the model with different batch sizes\n",
        "batch_sizes = [32, 64]\n",
        "for batch_size in batch_sizes:\n",
        "    print(f'Training with batch size: {batch_size}')\n",
        "    model.fit(x=[X_train_padded_A, X_train_padded_B], y=y_train,\n",
        "              epochs=100,\n",
        "              batch_size=batch_size,\n",
        "              validation_split=0.2,\n",
        "              verbose=1,\n",
        "              callbacks=[reduce_lr])\n",
        "\n",
        "# Evaluating the model on test data and printing results\n",
        "loss, accuracy = model.evaluate(x=[X_test_padded_A, X_test_padded_B], y=y_test)\n",
        "print(f'Test loss: {loss:.4f}')\n",
        "print(f'Test accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Two sentences for testing\n",
        "sentence_A = \"The speed is fast\"\n",
        "sentence_B = \"The speed is slow\"\n",
        "\n",
        "# Tokenizing and padding the test sentences\n",
        "test_seq_A = tokenizer.texts_to_sequences([sentence_A])\n",
        "test_seq_B = tokenizer.texts_to_sequences([sentence_B])\n",
        "test_padded_A = pad_sequences(test_seq_A, maxlen=max_sequence_length)\n",
        "test_padded_B = pad_sequences(test_seq_B, maxlen=max_sequence_length)\n",
        "\n",
        "# Making predictions\n",
        "predictions = model.predict([test_padded_A, test_padded_B])\n",
        "\n",
        "probability = predictions[0][0]\n",
        "print(f\"Sentence A: '{sentence_A}'\")\n",
        "print(f\"Sentence B: '{sentence_B}'\")\n",
        "print(f\"Prediction (probability of contradiction): {probability:.4f}\")\n",
        "\n",
        "# Determine prediction\n",
        "threshold = 0.4\n",
        "if probability > threshold:\n",
        "    prediction_result = \"Contradiction\"\n",
        "else:\n",
        "    prediction_result = \"No Contradiction\"\n",
        "\n",
        "print(f\"Prediction: {prediction_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZceh4Xl7Iz4",
        "outputId": "726cd415-b5f6-4956-8561-83ea79b3c686"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Sentence A: 'The speed is fast'\n",
            "Sentence B: 'The speed is slow'\n",
            "Prediction (probability of contradiction): 0.9395\n",
            "Prediction: Contradiction\n"
          ]
        }
      ]
    }
  ]
}